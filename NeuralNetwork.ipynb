{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "UcEwRrLXv3u9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch.nn.functional as F\n",
        "import matplotlib as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "MSvKoMYs2FVO"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  #input layer the 4 components\n",
        "  #hidden layer 1\n",
        "  #hidden layer 2\n",
        "  #output one of three types of flowers\n",
        "\n",
        "  def __init__(self, in_features = 28*28, h1=128, h2=64, out_features = 10):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features, h1)\n",
        "    self.fc2 = nn.Linear(h1,h2)\n",
        "    self.out = nn.Linear(h2,out_features)\n",
        "\n",
        "\n",
        "  #function that causes it to move forward\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28) #this is flattening the images\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "yRmkb8-G6C_U"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(41)\n",
        "\n",
        "model = Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "mosJIKaR719l"
      },
      "outputs": [],
      "source": [
        "numb_batch = 64\n",
        "T = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "train_data = torchvision.datasets.MNIST('mnist_data', train = True, download = True, transform = T)\n",
        "val_data = torchvision.datasets.MNIST('mnist_data', train = False, download = True, transform = T)\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_data, batch_size = numb_batch)\n",
        "val_dl = torch.utils.data.DataLoader(val_data, batch_size = numb_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "2sp5wHNp83rD"
      },
      "outputs": [],
      "source": [
        "X = np.array([np.array(train_data[i][0]).flatten() for i in range(len(train_data))])\n",
        "y = np.array([train_data[i][1] for i in range(len(train_data))])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "0ZGdg3VY-cHb"
      },
      "outputs": [],
      "source": [
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "0BbXDk3t_INs"
      },
      "outputs": [],
      "source": [
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DelZTqqLpXd",
        "outputId": "c9f5f537-8294-499f-94fc-f6b5a504b4ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch0 and loss 2.308845281600952\n",
            "Epoch10 and loss 0.5311505794525146\n",
            "Epoch20 and loss 0.3211958110332489\n",
            "Epoch30 and loss 0.23383580148220062\n",
            "Epoch40 and loss 0.17561687529087067\n",
            "Epoch50 and loss 0.13933373987674713\n",
            "Epoch60 and loss 0.11308976262807846\n",
            "Epoch70 and loss 0.09268690645694733\n",
            "Epoch80 and loss 0.07630958408117294\n",
            "Epoch90 and loss 0.06327781826257706\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(X_train)\n",
        "  loss = criterion(y_pred, y_train)\n",
        "\n",
        "  losses.append(loss.detach().numpy())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "KHJFsX32P7GD"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  y_eval = model.forward(X_test)\n",
        "  loss = criterion(y_eval, y_test)\n",
        "  loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "aNvwK6UzLU4i"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(X_test):\n",
        "    y_val = model.forward(data)\n",
        "\n",
        "\n",
        "    #the arg is the actual value and the test is what we ended up producing\n",
        "    if y_val.argmax().item() == y_test[i]:\n",
        "      correct += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2m92v0EP9Dk",
        "outputId": "9e427a48-8938-4f96-d0c7-6625ed4fb753"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11576"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "E0i-yMP1Qd9I"
      },
      "outputs": [],
      "source": [
        "state_dict = model.state_dict()\n",
        "weights = []\n",
        "biases = []\n",
        "\n",
        "# Iterate over the state_dict and store weights and biases in separate lists\n",
        "for param_tensor in state_dict:\n",
        "    if 'weight' in param_tensor:\n",
        "        weights.append(state_dict[param_tensor].numpy())\n",
        "    elif 'bias' in param_tensor:\n",
        "        biases.append(state_dict[param_tensor].numpy())\n",
        "\n",
        "data = {}\n",
        "for i, weight in enumerate(weights):\n",
        "    data[f'Layer {i+1} weights'] = weight.flatten()\n",
        "\n",
        "for i, bias in enumerate(biases):\n",
        "    data[f'Layer {i+1} biases'] = bias.flatten()\n",
        "\n",
        "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data.items()]))\n",
        "\n",
        "df.to_csv('model_weights_and_biases.csv', index=False)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
